https://medium.com/bb-tutorials-and-thoughts/250-practice-questions-for-terraform-associate-certification-7a3ccebe6a1a

Install Terraform
-----------------

1. Install chocolatey on windows of your laptop
https://chocolatey.org/install

2. Install terraform with below command:
choco install terraform

3. Follow below to install terraform in different OS
https://www.terraform.io/downloads

-----------------
terraform provider version constraint. version arugment is used to specify provider constraint.

terraform {
  required_providers {
    artifactory = {
      source = "jfrog/artifactory"
      version = "6.14.0"
    }
  }
}

provider "artifactory" {
  # Configuration options
}
-----------------
terraform version constraint. required_version is used to specify terraform version constraint.
terraform {
  required_providers {
    artifactory = {
      source = "jfrog/artifactory"
      version = "6.14.0"
    }
  required_version = "~>= 1.3.1"  
  }
}

provider "artifactory" {
  # Configuration options
}

-----------------------
How to upgrade/degrade terraform provider?
Either delete .terraform.lock.hcl file or terraform init -upgrade
-----------------------

Terraform workflow:
1. create/init
2. plan
3. apply

-----------------------

Create ec2.tf file:

provider "aws" {
  region     = "us-east-1"
  access_key = "XXXXX"
  secret_key = "XXXXX"
}

resource "aws_instance" "webvm" {
   ami = "ami-026b57f3c383c2eec"
   instance_type = "t2.micro"
}


terraform init
This will initializes a working directory containing configuration files and install pluggins for required providers.

terraform plan
It will let you preview the actions terraform would take to modify your infrastruture, or save plan which you can apply later.

terraform apply
This will execute the actions proposed in a terraform plan to create, update or destroy infrastructure.
----------

1. Create and execute plan for creation of resources:

terraform plan -out myplan.out
terraform apply myplan.out

This command will show you the content of plan:

terraform show -json myplan.out | jq

2. Create and execute plan for deletion of resources:

terraform plan -destroy -out destroy.out
terraform apply destroy.out


terraform destroy:
It will delete all resources mentioned in your configuration.

-----------------------
Destroy target resource: 
ResourceIdentifier: <resourcetype.localresourcename>
terraform destroy -target aws_iam_user.myuser -auto-approve

------
Few Examples:--
------
1. Create a rds db and take snapshot of that instance instance class db.t2.micro.
2. Create EBS volume and take snapshot of the EBS volume
3. Create EC2 instance and EBS volume and attach EBS volume to the instance.
4. Create Classic Load Balancer and register the EC2 instance with ELB.
5. Create 5 IAM users and 1 groups. Add all users to group.
6. Launch EC2 instance and install nginx using user data. Take AMI of that instance and then launch another machine using that AMI.
7. Create Lambda Function to print "hello world"
8. Create S3 bucket and attach simple policy to allow public read:
{
    "Version": "2012-10-17",
    "Statement": [
        {
            "Sid": "PublicRead",
            "Effect": "Allow",
            "Principal": "*",
            "Action": [
                "s3:GetObject",
                "s3:GetObjectVersion"
            ],
            "Resource": [
                "arn:aws:s3:::DOC-EXAMPLE-BUCKET/*"
            ]
        }
    ]
}
9. Create Security Group and open ingress and egress to 0.0.0.0/0.
10. Create VPC with 2 subnets.



1) We covered implicit dependency in terraform. by specifying resource identifier.attribute.

2) Terraform output 
output "volume_info" {
   value = "resource_identifier"
}

3) terraform sensitive variables. In case you don't want to print the exact value on console output. You can use sensitive = true as below:

output "volume_info" {
   value = "resource_identifier"
   sensitive = true
}

4) Reading the terraform documentation, resources, arguments refrences, attributes refrences

5. Terraform State File:
How terraform track what is created and what is destroyed? It maintains a database file locally where you are running terraform command from. State file stores state of infrastructure that is being used from TF files. Never touch/edit/update state file. Always consider backup of state file.
The state allows terraform to map real world resources to your existing configuration. 
AWS Demo:
Create EC2 Machine and a S3 bucket in AWS using terraform
Notice the tf state file
Remove the tfstate file
Run terraform plan and apply and try creating both EC2 machine and bucket.
Delete both EC2 machine and S3 bucket.
Create it again.


6. Terraform Data Source:-

1. Create provider.tf file
2. data.tf
data "aws_ami" "amznlinux" {
    most_recent = false
    owners = ["AWS-ACCT-Number"]
    filter {
        name = "name"
        values = ["*securedimage"]
    }
    filter {
        name = "root-device-type"
        values = ["ebs"]
    }
    filter {
        name = "virtualization-type"
        values = ["hvm"]
    }
    filter {
        name = "architecture"
        values = ["x86_64"]
    }
}
3. main.tf
resource "aws_instance" "webvm" {
   ami = data.aws_ami.amznlinux.id
   instance_type = "t2.micro"
   key_name = aws_key_pair.deployer.key_name
   user_data = file ("script.sh")
   vpc_security_group_ids = [aws_security_group.allow_ssh.id, aws_security_group.allow_web.id]
   tags = {
    "Name" = "Webserver"
   }
}
4. keypair.tf
resource "aws_key_pair" "deployer" {
  key_name   = "deployer-key"
  public_key = "ssh-rsa WF9***"
}

5. output.tf
output "myimage" {
    value = data.aws_ami.amznlinux.id
}
6.script.sh
#! /bin/bash
sudo yum update -y
sudo yum install -y httpd
sudo systemctl enable httpd
sudo service httpd start
echo "<h1>We are learning Terraform</h1>" | sudo tee /var/www/html/index.html

7. securitygroup.tf
resource "aws_security_group" "allow_ssh" {
  name        = "allow_ssh"
  description = "Allow SSH inbound traffic"
  ingress {
    description      = "Allow SSH"
    from_port        = 22
    to_port          = 22
    protocol         = "tcp"
    cidr_blocks      = ["0.0.0.0/0"]
  }

  egress {
    description      = "Allow all outgoing traffic"
    from_port        = 0
    to_port          = 0
    protocol         = "-1"
    cidr_blocks      = ["0.0.0.0/0"]
    ipv6_cidr_blocks = ["::/0"]
  }

  tags = {
    Name = "allow_ssh"
  }
}


resource "aws_security_group" "allow_web" {
  name        = "allow_apache"
  description = "Allow Apache inbound traffic"
  ingress {
    description      = "Allow web apache"
    from_port        = 80
    to_port          = 80
    protocol         = "tcp"
    cidr_blocks      = ["0.0.0.0/0"]
  }
  ingress {
    description      = "Allow SSL web apache"
    from_port        = 443
    to_port          = 443
    protocol         = "tcp"
    cidr_blocks      = ["0.0.0.0/0"]
  }

  egress {
    description      = "Allow all outgoing traffic"
    from_port        = 0
    to_port          = 0
    protocol         = "-1"
    cidr_blocks      = ["0.0.0.0/0"]
  }

  tags = {
    Name = "allow_apache"
  }
}

---------------------------------------
Explicit Dependency: Use switch depends_on

resource "aws_instance" "webvm01" {
   ami = "ami-026b57f3c383c2eec"
   instance_type = "t2.micro"
   availability_zone = "us-east-1b"
}

resource "aws_instance" "webvm02" {
   ami = "ami-026b57f3c383c2eec"
   instance_type = "t2.micro"
   availability_zone = "us-east-1b"
}

resource "aws_instance" "webvm03" {
   ami = "ami-026b57f3c383c2eec"
   instance_type = "t2.micro"
   availability_zone = "us-east-1b"
   depends_on = [ aws_instance.webvm01, aws_instance.webvm02 ]
}


------------------------------------------------------
LifeCycle:
------------------------------------------------------
1. condition:

resource "aws_instance" "example" {
  instance_type = "t2.micro"
  ami           = data.aws_ami.example.id

  lifecycle {
    precondition {
      condition     = data.aws_ami.example.architecture == "x86_64"
      error_message = "The selected AMI must be for the x86_64 architecture."
    }

    # The EC2 instance must be allocated a public DNS hostname.
    postcondition {
      condition     = self.public_dns != ""
      error_message = "EC2 instance must be in a VPC that has public DNS hostnames enabled."
    }
  }
}

data "aws_ebs_volume" "example" {
  filter {
    name = "volume-id"
    values = [aws_instance.example.root_block_device[0].volume_id]
  }

  lifecycle {
    # The EC2 instance will have an encrypted root volume.
    postcondition {
      condition     = self.encrypted == true
      error_message = "The server's root volume is not encrypted."
    }
  }
}

output "api_base_url" {
  value = "https://${aws_instance.example.public_dns}:8433/"
}

2. create before destroy
resource "aws_instance" "webvm02" {
   ami = "ami-026b57f3c383c2eec"
   instance_type = "t2.medium"
   availability_zone = "us-east-1b"
   lifecycle {
    create_before_destroy = true
  }   
}
3. ignore_changes
resource "aws_instance" "webvm02" {
   ami = "ami-026b57f3c383c2eec"
   instance_type = "t2.medium"
   availability_zone = "us-east-1b"
   lifecycle {
    ignore_changes  = [ tags ]
  }   
}
4. precondition
variable "ami" {
    default = "ami-026b57f3c383c2eec"
}

resource "aws_instance" "webvm02" {
   ami = var.ami
   instance_type = "t2.medium"
   availability_zone = "us-east-1b"
   lifecycle {
     precondition {
       condition     = length(var.ami) == 21 && substr(var.ami, 0, 4) == "ami-"
       error_message = "The selected AMI must have 21 characters and starts with string ami-."
    }
  }   
}

5. prevent _destroy

resource "aws_instance" "webvm02" {
   ami = "ami-026b57f3c383c2eec"
   instance_type = "t2.medium"
   availability_zone = "us-east-1b"
   lifecycle {
    prevent_destroy = true
  }   
}
6. replace_triggered_by

resource "aws_instance" "webvm02" {
   ami = "ami-026b57f3c383c2eec"
   instance_type = "t2.micro"
   availability_zone = "us-east-1b"
   lifecycle {
    replace_triggered_by  = [ aws_s3_bucket.b ]
  }   
}

resource "aws_s3_bucket" "b" {
  bucket = "my-tf-test-bucket121232"
  force_destroy = true
}

----------------------------------------------------
Variables:
----------------------------------------------------
# Input Variables
variable "aws_region" {
  description = "Region in which AWS resources to be created"
  type        = string
  default     = "us-east-1"
}


variable "ec2_ami_id" {
  description = "AMI ID"
  type        = string
  default     = "ami-0915bcb5fa77e4892" # Amazon2 Linux AMI ID
}

variable "ec2_instance_type" {
  description = "EC2 Instance Type"
  type        = string
  default     = "t2.micro"
}

variable "ec2_instance_count" {
  description = "EC2 Instance Count"
  type        = number
  default     = 2
}


main.tf
resource "aws_instance" "webvm" {
   ami = data.aws_ami.amznlinux.id
   instance_type = var.ec2_instance_type
   key_name = aws_key_pair.deployer.key_name
   user_data = file ("script.sh")
   count = var.ec2_instance_count
   vpc_security_group_ids = [aws_security_group.allow_ssh.id, aws_security_group.allow_web.id]
   tags = {
    "Name" = "Webserver"
   }
}

Create other resources on your own.
If you don't specify default values in the variables.tf file then it will prompt from the user during execution.

Variable overriding using CLI and environment variables:
# Option-1 (Always provide -var for both plan and apply)
# Review the terraform plan
terraform plan -var="ec2_instance_type=t3.large" -var="ec2_instance_count=1"

# Create Resources (optional)
terraform apply -var="ec2_instance_type=t3.large" -var="ec2_instance_count=1"

# Option-2 (Generate plan file with -var and use that with apply)
# Generate Terraform plan file
terraform plan -var="ec2_instance_type=t3.large" -var="ec2_instance_count=1" -out plan.out

# Create / Deploy Terraform Resources using Plan file
terraform apply plan.out 

----------------------------
# SET Environment Variables
export TF_VAR_ec2_instance_count=1
export TF_VAR_ec2_instance_type=t2.medium
echo $TF_VAR_ec2_instance_count, $TF_VAR_ec2_instance_type

unset TF_VAR_ec2_instance_count
unset TF_VAR_ec2_instance_type
echo $TF_VAR_ec2_instance_count, $TF_VAR_ec2_instance_type

------
1. 
If the file name is terraform.tfvars, terraform will auto-load the variables present in this file by overriding the default values in variables.tf.

2. 
You can create file with your own name and assign value to variable. Use that -var-file while creating plan or apply.


terraform plan -var-file="custom.tfvars"

3. Create a file custom.auto.tfvars. With this extension, whatever may be the file name, the variables inside these files will be auto loaded during terraform plan or apply

ec2_instance_type  = "r4.large"

-------------
List: Variables
------------
variable "ec2_instance_type" {
  description = "EC2 Instance Type"
  type = list(string)
  default = ["t3.micro", "t3.small", "t3.large"]
}

call this variable using var.ec2_instance_type[0], var.ec2_instance_type[1] and var.ec2_instance_type[2] in your main.tf file

----------------
Map: Variables
----------------
variable "ec2_instance_type" {
  description = "EC2 Instance Type"
  type = map(string)
  default = {
    us-east-1 = "t2.micro"
    us-west-2 = "t2.nano"
    ap-south-1 = "t2.small"
  }
}

call this variable using ec2_instance_type.us-east-1, ec2_instance_type.us-west-2 and ec2_instance_type.ap-south-1 etc

--------------------
Count and condition example
-------------------
resource "aws_instance" "webvm" {
   ami = data.aws_ami.amznlinux.id
   instance_type = var.ec2_instance_type["us-west-2"]
   key_name = aws_key_pair.deployer.key_name
   user_data = file ("script.sh")
   vpc_security_group_ids = [aws_security_group.allow_ssh.id, aws_security_group.allow_web.id]
   tags = var.common_tags
   count = var.servertype == "webserver" ? 1 : 0
}

resource "aws_instance" "appvm" {
   ami = data.aws_ami.amznlinux.id
   instance_type = var.ec2_instance_type["us-east-1"]
   key_name = aws_key_pair.deployer.key_name
   user_data = file ("script.sh")
   vpc_security_group_ids = [aws_security_group.allow_ssh.id, aws_security_group.allow_web.id]
   tags = var.common_tags
   count = var.servertype == "appserver" ? 1 : 0 
}

------------------------------
/*
resource "aws_iam_user" "iamuser" {
#  name = "myuser-${count.index}"
  name = var.usernames[count.index]    
  path = "/system/"
  count = 3
}
*/
resource "aws_iam_user" "iamuser" {
  for_each = toset( ["rizwan", "devuser","fakeuser", "stguser", "produser", "prod1"] )
  name     = each.key
}

one more example
resource "aws_instance" "myec2" {
  ami = "ami-0cea098ed2ac54925"
  for_each  = {
      devkey = "t2.micro"
      stgkey = "t2.medium"
      prdkey = "r5.large"
   }
  instance_type    = each.value
  key_name         = each.key
  tags =  {
   Name = each.value
    }
}

-------
validations
---------
variable "ec2_ami_id" {
  description = "AMI ID"
  type        = string
  validation {
    condition = length(var.ec2_ami_id) > 4 && substr(var.ec2_ami_id, 0, 4) == "ami-"
    error_message = "The ec2_ami_id value must be a valid AMI id, starting with \"ami-\"."
  }
}

------
boolean
------
variable "ec2_instance_count" {
  description = "EC2 Instance Count"
  type        = bool
}

-------
# Create S3 Bucket - with Input Variables 
/*
resource "aws_s3_bucket" "mys3bucket" {
  bucket = "${var.app_name}-${var.environment_name}-bucket"
  acl = "private"
  tags = {
    Name = "${var.app_name}-${var.environment_name}-bucket"
    Environment = var.environment_name
  }
}
*/

# Define Local Values
locals {
  bucket-name = "${var.app_name}-${var.environment_name}-bucket" # Complex expression
}

# Create S3 Bucket - with Input Variables & Local Values
resource "aws_s3_bucket" "mys3bucket" {
  bucket = local.bucket-name
  tags = {
    Name = local.bucket-name
    Environment = var.environment_name
  }
}



resource "aws_instance" "app-dev" {
   ami = "ami-082b5a644766e0e6f"
   instance_type = "t2.micro"
   tags = local.common_tags
}

resource "aws_instance" "db-dev" {
   ami = "ami-082b5a644766e0e6f"
   instance_type = "t2.small"
   tags = local.common_tags
}

resource "aws_ebs_volume" "db_ebs" {
  availability_zone = "${var.aws_region}-a"
  size              = 8
  tags = local.common_tags
}

locals {
  common_tags = {
    Owner = "DevOps Team"
    service = "backend"
  }
}

# Input Variables
variable "aws_region" {
  description = "Region in which AWS Resources to be created"
  type = string
  default = "us-east-1"
}

# App Name S3 Bucket used for
variable "app_name" {
  description = "Application Name"
  type = string
}

# Environment Name
variable "environment_name" {
  description = "Environment Name"
  type = string
}



-----------------------------------




----------------------------------------------------
Null Resource
-----------------------------------------------------
resource "aws_eip" "elasticIP" {
    vpc = true
    depends_on = [ null_resource.check_endpoint ]
}

resource "null_resource" "check_endpoint" {
    provisioner "local-exec" {
      command = "curl https://google.com"
    }
}
----------------------------------------------------
DynamicBlock
-----------------------------------------------------
resource "aws_security_group" "allow_ssh_web" {
  name        = "dynamic-sg"
  description = "Ingress for SSH and Web"

  dynamic "ingress" {
    for_each = var.sg_ports
    iterator = port
    content {
      from_port   = port.value
      to_port     = port.value
      protocol    = "tcp"
      cidr_blocks = ["0.0.0.0/0"]
    }
  }

  dynamic "egress" {
    for_each = var.sg_ports
    content {
      from_port   = egress.value
      to_port     = egress.value
      protocol    = "tcp"
      cidr_blocks = ["0.0.0.0/0"]
    }
  }
}


----------------------------------------------------
workspace and multiple provider
-----------------------------------------------------

### This is multi provider example
provider "aws" {
  alias      = "east2"
  region     = "us-east-2"
  access_key = "AKIAYC5UVKRADAWZGVGH"
  secret_key = "cfl6f/t3xgaFaCYfX/csmnBcRd9VvYRfxeNBGsz9"
}



/*
resource "aws_instance" "ec2" {
    ami = "ami-0645b47beb2163eae"
    instance_type = "t2.micro"
    count = terraform.workspace == "default" ? 1 : 0
}
*/

resource "aws_instance" "ec2" {
    provider = aws.east2
    ami = "ami-0645b47beb2163eae"
    instance_type = lookup(var.ec2type,terraform.workspace,"t2.medium")
#    count = terraform.workspace == "default" ? 1 : 0
}

variable "ec2type"  {
    type = map
    default = {
        default = "t2.medium"
        dev = "t2.micro"
        stage = "t2.large"
        prod = "r5.large"
    }
}



----------------------------------------------------
caching
-----------------------------------------------------
https://developer.hashicorp.com/terraform/cli/config/config-file

----------------------------------------------------
import used to bring services in control of terraform whch are created outside of terraform
-----------------------------------------------------
terraform improt <resource identifier> <real resourceid>


----------------------------------------------------
terraform fmt and terraform validate commands are used to format the syntac and do the syntax validation 
-----------------------------------------------------


----------------------------------------------------
Terraform cloud and sentinel and remote state management
-----------------------------------------------------
terraform {
	backend "remote" {
		organization = "my-org" # org name from step 2.
		workspaces {
			name = "my-app" # name for your app's state.
		}
	}
}

CLI or VSC integrated workspaces

----------------------------------------------------
Terraform cloud and sentinel and remote state management
-----------------------------------------------------

----------------------------------------------------
Terraform graph is used to see visualized form of all resources to be created throgh terraform
-----------------------------------------------------

----------------------------------------------------
terraform taint will taint the resources so that when you apply terraform next time it will recreate the resources
-----------------------------------------------------

----------------------------------------------------
terraform modules inbuild and custom modules and also can use github as the source
remember how to get value to module variables
remember null resources used in module
dependency explicit and implicit
-----------------------------------------------------






